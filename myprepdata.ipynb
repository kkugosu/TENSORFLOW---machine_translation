{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "from gensim.models import word2vec\n",
    "import nltk\n",
    "import os,sys\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download('movie_reviews')\n",
    "#from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#documents = [movie_reviews.words(fileid)\n",
    "#             for fileid in movie_reviews.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print (documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wv_model_en.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wv_model_en.train(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wv_model_en.save('en_wv_model')\n",
    "#pprint(wv_model_en.most_similar('plot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconfig = {\\'workers\\' : multiprocessing.cpu_count()}\\nwv_model_en = word2vec.Word2Vec(**config)\\nif ( os.path.isfile(\"./en_wv_model2\") == False):\\n    results = []\\n    with open(\\'./tok_dataset/train.tok.clean.bpe.32000.en\\') as inputfile:\\n        for line in inputfile:\\n            results.append(line.strip().split(\\' \\'))\\n    print (results[0])\\n    wv_model_en.build_vocab(results)\\n    wv_model_en.train(results)\\n    wv_model_en.save(\\'en_wv_model2\\')\\nwv_model_en = word2vec.Word2Vec.load(\\'en_wv_model2\\')\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "config = {'workers' : multiprocessing.cpu_count()}\n",
    "wv_model_en = word2vec.Word2Vec(**config)\n",
    "if ( os.path.isfile(\"./en_wv_model2\") == False):\n",
    "    results = []\n",
    "    with open('./tok_dataset/train.tok.clean.bpe.32000.en') as inputfile:\n",
    "        for line in inputfile:\n",
    "            results.append(line.strip().split(' '))\n",
    "    print (results[0])\n",
    "    wv_model_en.build_vocab(results)\n",
    "    wv_model_en.train(results)\n",
    "    wv_model_en.save('en_wv_model2')\n",
    "wv_model_en = word2vec.Word2Vec.load('en_wv_model2')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pprint(wv_model_en.most_similar('she'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wv_model_en.most_similar(positive = [myarray],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wv_model_en.wv['she'] #[100] float array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myarray = np.array([-0.67258787, -4.15615225, -1.72683489,  1.6745466 , -0.66765279,\n",
    "        1.20479822, -0.54290372, -0.17763264, -6.63635206, -3.36331749,\n",
    "       -1.20754302, -4.75114679,  3.3733356 , -2.00328326,  1.61597621,\n",
    "       -2.5903039 ,  3.89082551,  2.05730581, -0.37433237, -1.15445471,\n",
    "        0.9606185 ,  4.23989391,  1.05038905, -1.0970273 , -3.27382827,\n",
    "        1.57637691, -4.19764471, -2.15746975,  2.48696518, -0.61238277,\n",
    "       -1.74696052, -0.37781578,  0.34524947,  2.54945087, -1.64452887,\n",
    "        0.57680875, -0.14833695,  1.02612078, -0.26212877, -0.51345897,\n",
    "       -1.39085841,  0.09278773, -1.48713863, -0.46643406,  7.02497864,\n",
    "        2.74286199, -0.83628732, -1.48309898, -0.32239187, -3.01059842,\n",
    "        1.07048142, -3.00496078,  0.34531841,  3.417485  ,  2.11597872,\n",
    "        0.14785768,  0.43224403,  0.61093956, -2.73394179, -1.91496217,\n",
    "       -2.31602764,  2.11022353,  3.03709865,  0.61163723,  0.87978035,\n",
    "       -1.34368658, -4.88440132, -1.7299546 , -0.21339908, -1.17470872,\n",
    "       -2.59537339,  1.38333321,  0.88531542,  0.43189961,  1.67749929,\n",
    "       -1.24953771,  1.51133716, -1.71328628,  2.10449433,  0.8787359 ,\n",
    "        4.48812008, -0.84192741,  3.90984416,  0.00753402,  2.64509892,\n",
    "        2.40421772,  1.52942765, -1.00621092, -0.50308841,  0.01391463,\n",
    "       -0.20117365,  1.02307236,  4.01931715, -0.79575706,  0.7374779 ,\n",
    "        1.36256838, -1.06702769, -0.8350783 ,  0.61838496,  1.31033885], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nresults = []\\nwith open('./tok_dataset/train.tok.clean.bpe.32000.en') as inputfile:\\n    for line in inputfile:\\n        #np.append(results,line,axis=0)\\n        results.append(line.strip())\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "results = []\n",
    "with open('./tok_dataset/train.tok.clean.bpe.32000.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        #np.append(results,line,axis=0)\n",
    "        results.append(line.strip())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(results) # 450096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#type(results[0]) # str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(results[0]) # 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(results[0].split(' ')) # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#results[0].split(' ')[0] # 'Res@@'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#amount(results[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wv_model_en.wv[results[0].split(' ')[0]] # [100] float array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reswv = [[]]\n",
    "#count = 0\n",
    "#for newresults in results:\n",
    "#    count = count+1\n",
    "#    print(count)\n",
    "#    prereswv = []\n",
    "#    for i in newresults.split(' '):\n",
    "#        prereswv.append(wv_model_en.wv[i])\n",
    "#        \n",
    "#    reswv.append(prereswv)  ---------> vector per sentence is impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class prep(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        config = {'workers' : multiprocessing.cpu_count()}\n",
    "        \n",
    "        self.wv_model_en = word2vec.Word2Vec(**config)\n",
    "        self.wv_model_de = word2vec.Word2Vec(**config)\n",
    "        \n",
    "        if ( os.path.isfile(\"./en_wv_model\") == False): ##wvmodel for eng\n",
    "            print(\"making en_model..\")\n",
    "            self.results = []\n",
    "            with open('./tok_dataset/train.tok.clean.bpe.32000.en') as inputfile:\n",
    "                for line in inputfile:\n",
    "                    self.results.append(line.strip().split(' '))\n",
    "            #print (results[0])\n",
    "            self.wv_model_en.build_vocab(self.results)\n",
    "            self.wv_model_en.train(self.results)\n",
    "            self.wv_model_en.save('en_wv_model2')\n",
    "        \n",
    "        if ( os.path.isfile(\"./de_wv_model\") == False): ##wvmodel for den\n",
    "            print(\"making de_model..\")\n",
    "            self.deresults = []\n",
    "            with open('./tok_dataset/train.tok.clean.bpe.32000.de') as inputfile:\n",
    "                for line in inputfile:\n",
    "                    self.deresults.append(line.strip().split(' '))\n",
    "            print (self.deresults[0])\n",
    "            self.wv_model_de.build_vocab(self.deresults)\n",
    "            print (\"training..\")\n",
    "            self.wv_model_de.train(self.deresults)\n",
    "            self.wv_model_de.save('de_wv_model')\n",
    "        \n",
    "        \n",
    "     \n",
    "        self.wv_model_en = word2vec.Word2Vec.load('en_wv_model')\n",
    "        self.wv_model_de = word2vec.Word2Vec.load('de_wv_model')\n",
    "\n",
    "        \n",
    "        self.results = []\n",
    "        with open('./tok_dataset/train.tok.clean.bpe.32000.en') as inputfile:\n",
    "            for line in inputfile:\n",
    "                #np.append(results,line,axis=0)\n",
    "                self.results.append(line.strip())\n",
    "        \n",
    "        self.deresults = []\n",
    "        with open('./tok_dataset/train.tok.clean.bpe.32000.de') as inputfile:\n",
    "            for line in inputfile:\n",
    "                #np.append(results,line,axis=0)\n",
    "                self.deresults.append(line.strip())\n",
    "        \n",
    "        print (self.wv_model_de.wv[self.deresults[0].split(' ')[0]])\n",
    "        \n",
    "    def prepare_line(self): #per sentence\n",
    "        return self.results\n",
    "    \n",
    "    def de_prepare_line(self): #per sentence\n",
    "        return self.deresults\n",
    "    \n",
    "    def get_wvmodel(self): #w2v\n",
    "        return self.wv_model_en\n",
    "    \n",
    "    def de_get_wvmodel(self): #w2v\n",
    "        return self.wv_model_de\n",
    "    \n",
    "    def get_maxlength(self):\n",
    "        i = 0\n",
    "        maxl = 0\n",
    "        ind = 0\n",
    "        while i < len(self.results):\n",
    "            if (maxl < len(self.results[i].split(' '))):\n",
    "                maxl = len(self.results[i].split(' '))\n",
    "                ind = i\n",
    "                print(ind)\n",
    "            i = i + 1\n",
    "        print(self.results[10])\n",
    "        return maxl\n",
    "\n",
    "    def findwordsfromvec(myarray):\n",
    "        return wv_model_en.most_similar(positive = [myarray],topn=1)\n",
    "\n",
    "    def findvecfromwords(myword):\n",
    "        return wv_model_en.wv(myword)\n",
    "\n",
    "    def tensorremake(tensor):\n",
    "        return newtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(results[10000].split(' ')) # 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class trsdata(object):\n",
    "#    def __init__(self):\n",
    "#        self.data = neres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from konlpy.tag import Kkma, Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(Kkma().pos(\"오버워치\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Twitter().pos(\"오버워치\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import codecs\n",
    "#tagger = Twitter()\n",
    "#corpus = codecs.open('corpus.txt', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def flat(content):\n",
    "#    return [\"{}/{}\".format(word, tag) for word, tag in tagger.pos(content)]\n",
    "\n",
    "#corpus.write(' '.join(flat(\"메이드복 입은 제이미 귀엽다\")) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import codecs\n",
    "\n",
    "#def read_data(filename):\n",
    "#    with codecs.open(filename, encoding='utf-8', mode='r') as f:\n",
    "#        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "#        data = data[1:]   # header 제외\n",
    "#    return data\n",
    "\n",
    "#train_data = read_data('/home/dockeruser/data/nsmc/ratings_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
